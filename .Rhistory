### mask by glaciers and available land ###
daltonAges <- read.csv('/Volumes/lj_mac_22/Dalton et al 2020 QSR Ice Layers/Dalton et al 2020 QSR Dates from Shapefile Names.csv')
# mask by land (for visualization) #
for (countTime in seq_along(times)) {
time <- times[countTime]
# land mask
land <- raster(paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/ccsm/tifs/',
time, 'BP/an_avg_TMAX.tif'))
# land <- land * 0 + 1
land <- projectRaster(land, maps)
land <- land * 0 + 1
maps[[countTime]] <- maps[[countTime]] * land
}
### mask by ice (for calculating BV) ###
mapsMasked <- maps
for (countTime in seq_along(times)) {
time <- times[countTime]
# ice mask
closestDalton <- which.min(abs(-1000 * daltonAges$calKiloYear - time))
load(paste0('/Volumes/lj_mac_22/Dalton et al 2020 QSR Ice Layers/RDA Files/daltonEtAl2020_',
sprintf('%.2f', daltonAges$calKiloYear[closestDalton]), '_kiloCalYBP.rda'))
daltonIce <- sp::spTransform(daltonIce, getCRS('albersNA', TRUE))
daltonIce <- rasterize(daltonIce, maps)
daltonIceMask <- calc(daltonIce, fun=function(x) ifelse(is.na(x), 1, NA))
mapsMasked[[countTime]] <- mapsMasked[[countTime]] * daltonIceMask
}
writeRaster(stack(maps),
paste0('/Volumes/lj_mac_22/pollen/predictions-',
toupper(genus), '_meanpred_landMask.tif'),
format = 'GTiff', overwrite = T)
writeRaster(stack(mapsMasked),
paste0('/Volumes/lj_mac_22/pollen/predictions-',
toupper(genus), '_meanpred_iceMask.tif'),
format = 'GTiff', overwrite = T)
}
return(stack(paste0('/Volumes/lj_mac_22/pollen/predictions-',
toupper(genus),
'_meanpred_iceMask.tif')))
}
# identify study region
studyRegionRasts <- getPollen(climYears)
for (gcm in gcmList) {
gcm <- gsub('\'', '', gcm)
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionRasts <- getPollen(climYears)
names(studyRegionRasts) <- c(paste0(tools::toTitleCase(genus),
"_pollen_predictions_", 0:21, "kybp"))
envData <- getClimRasts(pc, climYear) # retrieve clipped env data for given climate year
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
print('line 615')
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
print('line 619')
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- paste0(baseFolder,
'background_sites/Random Background Sites across Study Region.Rdata')
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
# otherwise, define bg points
if(!file.exists(bgFileName)) getBG(bgFileName, calibRegionSpAlb)
load(bgFileName)
print('line 656')
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
if(!dir.exists(paste0('./models/predictions/', speciesAb_))) dir.create(paste0('./models/predictions/', speciesAb_))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
# remove XML file if it's created
file.remove(list.files(path = paste0('./models/predictions/', speciesAb_, '/'),
pattern = '.xml',
full.names = T))
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(range, border = 'blue', main = paste0('Maxent output, ', sp))
plot(envMap, add = TRUE)
plot(range, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(range, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.rData')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(bg, range, envMap, envModel, records, file = outputFileName, overwrite = T)
# put study regions in reverse order (from 21 KYBP to 0 KYBP)
studyRegionRasts <- unstack(studyRegionRasts)
studyRegionRasts <- stack(rev(studyRegionRasts))
if(!dir.exists('./predictions')) dir.create('./predictions') # create directory to store predictions
if(exists('preds')) rm(preds)
preds <- getPredictions(speciesAb_, pc)
preds <- projectRaster(preds, studyRegionRasts) # project predictions to study region
## mask by study region and force values to be within [0, 1] ##
# because the rasters can get pushed outside this during re-projection #
preds <- raster::calc(preds, fun = function(x) ifelse(x < 0, 0, x))
preds <- raster::calc(preds, fun = function(x) ifelse(x > 1, 1, x))
for (i in 1:nlayers(preds)) {
landMask <- (1 - studyRegionRasts[[i]])
preds[[i]] <- preds[[i]] * landMask
}
# names(preds) <- paste0('ybp', seq(21000, 0, by=-1000)) # rename rasters to respective year
if(!dir.exists(paste0('./predictions/', gcm))) dir.create(paste0('./predictions/', gcm))
writeRaster(stack(preds), paste0('./predictions/', gcm, '/', speciesAb_, '_GCM_', gcm, '_PC', pc),
format = 'GTiff', overwrite = T)
file.remove(list.files(path = paste0('./predictions/', gcm),
pattern = '.xml',
full.names = T))
save.image(paste0('./workspaces/06 - predictions (', gcm, ')'))
}
for (gcm in gcmList) {
gcm <- gsub('\'', '', gcm)
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionRasts <- getPollen(climYears)
names(studyRegionRasts) <- c(paste0(tools::toTitleCase(genus),
"_pollen_predictions_", 0:21, "kybp"))
envData <- getClimRasts(pc, climYear) # retrieve clipped env data for given climate year
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
print('line 615')
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
print('line 619')
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- paste0(baseFolder,
'background_sites/Random Background Sites across Study Region.Rdata')
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
# otherwise, define bg points
if(!file.exists(bgFileName)) getBG(bgFileName, calibRegionSpAlb)
load(bgFileName)
print('line 656')
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
if(!dir.exists(paste0('./models/predictions/', speciesAb_))) dir.create(paste0('./models/predictions/', speciesAb_))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
# remove XML file if it's created
file.remove(list.files(path = paste0('./models/predictions/', speciesAb_, '/'),
pattern = '.xml',
full.names = T))
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(range, border = 'blue', main = paste0('Maxent output, ', sp))
plot(envMap, add = TRUE)
plot(range, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(range, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.rData')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(bg, range, envMap, envModel, records, file = outputFileName, overwrite = T)
# put study regions in reverse order (from 21 KYBP to 0 KYBP)
studyRegionRasts <- unstack(studyRegionRasts)
studyRegionRasts <- stack(rev(studyRegionRasts))
if(!dir.exists('./predictions')) dir.create('./predictions') # create directory to store predictions
if(exists('preds')) rm(preds)
preds <- getPredictions(speciesAb_, pc)
preds <- projectRaster(preds, studyRegionRasts) # project predictions to study region
## mask by study region and force values to be within [0, 1] ##
# because the rasters can get pushed outside this during re-projection #
preds <- raster::calc(preds, fun = function(x) ifelse(x < 0, 0, x))
preds <- raster::calc(preds, fun = function(x) ifelse(x > 1, 1, x))
for (i in 1:nlayers(preds)) {
landMask <- (1 - studyRegionRasts[[i]])
preds[[i]] <- preds[[i]] * landMask
}
# names(preds) <- paste0('ybp', seq(21000, 0, by=-1000)) # rename rasters to respective year
if(!dir.exists(paste0('./predictions/', gcm))) dir.create(paste0('./predictions/', gcm))
writeRaster(stack(preds), paste0('./predictions/', gcm, '/', speciesAb_, '_GCM_', gcm, '_PC', pc),
format = 'GTiff', overwrite = T)
file.remove(list.files(path = paste0('./predictions/', gcm),
pattern = '.xml',
full.names = T))
save.image(paste0('./workspaces/06 - predictions (', gcm, ')'))
}
for (gcm in gcmList) {
gcm <- gsub('\'', '', gcm)
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionRasts <- getPollen(climYears)
names(studyRegionRasts) <- c(paste0(tools::toTitleCase(genus),
"_pollen_predictions_", 0:21, "kybp"))
envData <- getClimRasts(pc, climYear) # retrieve clipped env data for given climate year
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
print('line 615')
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
print('line 619')
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- paste0(baseFolder,
'background_sites/Random Background Sites across Study Region.Rdata')
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
# otherwise, define bg points
if(!file.exists(bgFileName)) getBG(bgFileName, calibRegionSpAlb)
load(bgFileName)
print('line 656')
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
if(!dir.exists(paste0('./models/predictions/', speciesAb_))) dir.create(paste0('./models/predictions/', speciesAb_))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
# remove XML file if it's created
file.remove(list.files(path = paste0('./models/predictions/', speciesAb_, '/'),
pattern = '.xml',
full.names = T))
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(range, border = 'blue', main = paste0('Maxent output, ', sp))
plot(envMap, add = TRUE)
plot(range, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(range, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.rData')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(bg, range, envMap, envModel, records, file = outputFileName, overwrite = T)
# put study regions in reverse order (from 21 KYBP to 0 KYBP)
studyRegionRasts <- unstack(studyRegionRasts)
studyRegionRasts <- stack(rev(studyRegionRasts))
if(!dir.exists('./predictions')) dir.create('./predictions') # create directory to store predictions
if(exists('preds')) rm(preds)
preds <- getPredictions(speciesAb_, pc)
preds <- projectRaster(preds, studyRegionRasts) # project predictions to study region
## mask by study region and force values to be within [0, 1] ##
# because the rasters can get pushed outside this during re-projection #
preds <- raster::calc(preds, fun = function(x) ifelse(x < 0, 0, x))
preds <- raster::calc(preds, fun = function(x) ifelse(x > 1, 1, x))
for (i in 1:nlayers(preds)) {
landMask <- (1 - studyRegionRasts[[i]])
preds[[i]] <- preds[[i]] * landMask
}
# names(preds) <- paste0('ybp', seq(21000, 0, by=-1000)) # rename rasters to respective year
if(!dir.exists(paste0('./predictions/', gcm))) dir.create(paste0('./predictions/', gcm))
writeRaster(stack(preds), paste0('./predictions/', gcm, '/', speciesAb_, '_GCM_', gcm, '_PC', pc),
format = 'GTiff', overwrite = T)
file.remove(list.files(path = paste0('./predictions/', gcm),
pattern = '.xml',
full.names = T))
save.image(paste0('./workspaces/06 - predictions (', gcm, ')'))
}
